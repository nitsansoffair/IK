# Project Summary
This project involves a Colab notebook that analyzes Knesset videos, extracting features from text and audio to create similarity graphs between speakers. 
The source code implements the experiments by calculating similarity using various functions for text, audio, and multimodal data. 
The paper provides an in-depth description of the methodology, experimental setup, results, and insights gained from the project. 
It also explores the advantages of multimodal similarity over text or audio-only approaches.

# Installation
$ conda env create -f environment.yml

# Running an Experiment
$ sh ./experiment.sh